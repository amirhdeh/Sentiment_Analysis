{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "colab": {
      "name": "LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCpbzsk0UTVG",
        "outputId": "f438e1c4-f6bc-483f-e4f8-8e5c69e085e4"
      },
      "source": [
        "!pip install hazm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting hazm\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/13/5a7074bc11d20dbbb46239349ac3f85f7edc148b4cf68e9b8c2f8263830c/hazm-0.7.0-py3-none-any.whl (316kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 4.6MB/s \n",
            "\u001b[?25hCollecting libwapiti>=0.2.1; platform_system != \"Windows\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/0f/1c9b49bb49821b5856a64ea6fac8d96a619b9f291d1f06999ea98a32c89c/libwapiti-0.2.1.tar.gz (233kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 18.3MB/s \n",
            "\u001b[?25hCollecting nltk==3.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/09/3b1755d528ad9156ee7243d52aa5cd2b809ef053a0f31b53d92853dd653a/nltk-3.3.0.zip (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 20.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from libwapiti>=0.2.1; platform_system != \"Windows\"->hazm) (1.15.0)\n",
            "Building wheels for collected packages: libwapiti, nltk\n",
            "  Building wheel for libwapiti (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for libwapiti: filename=libwapiti-0.2.1-cp37-cp37m-linux_x86_64.whl size=154454 sha256=467a4b2627371b9a02c35572b80ac646754d81536433c73106ac2db15c541052\n",
            "  Stored in directory: /root/.cache/pip/wheels/66/15/54/4510dce8bb958b1cdd2c47425cbd1e1eecc0480ac9bb1fb9ab\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.3-cp37-none-any.whl size=1394488 sha256=2436ef2daf4281cedb9921fd094c4a230fa2e083c35e505cc407e24fef0e5e47\n",
            "  Stored in directory: /root/.cache/pip/wheels/d1/ab/40/3bceea46922767e42986aef7606a600538ca80de6062dc266c\n",
            "Successfully built libwapiti nltk\n",
            "Installing collected packages: libwapiti, nltk, hazm\n",
            "  Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "Successfully installed hazm-0.7.0 libwapiti-0.2.1 nltk-3.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "Bo12I77_Vscf"
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D, Input, merge, Add, Concatenate, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from sklearn.utils import resample\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "from hazm import *\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4y8OeZhcWxJS",
        "outputId": "3f9a00fc-6288-42e9-c4a9-531276bec4dd"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('./drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at ./drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DO-3GJp0hDei"
      },
      "source": [
        "sent = pd.read_csv('./drive/My Drive/PersianSWN.csv', header=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjNr5S4rhPHv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "c89a46f9-8907-4a5c-f75d-5e2b4e0d33c6"
      },
      "source": [
        "sentiment = {}\n",
        "for row in sent[0]:\n",
        "  temp = row.split('\\t')\n",
        "  name = temp[1]\n",
        "  if name in sentiment:\n",
        "    sentiment[name][0].append((float(temp[2])) * (float(temp[3])))\n",
        "    sentiment[name][1].append((float(temp[2])) * (float(temp[4])))\n",
        "  else:\n",
        "    sentiment[name] = [[float(temp[2]) * float(temp[3])], [float(temp[2]) * float(temp[4])]]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-5e8b96c7cd2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msentiment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentiment\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'sent' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4rMMrJzqB-1"
      },
      "source": [
        "for name in sentiment:\n",
        "  temp = sentiment[name]\n",
        "  sentiment[name] = [np.mean(temp[0]), np.mean(temp[1])]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFshGVwtqrcP",
        "outputId": "36bdb3b5-80c5-4278-a6ae-d0e47dbe35a6"
      },
      "source": [
        "print(sentiment['توانا'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.08496527777777779, 0.02597222222222222]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rO-g-YaeW64c"
      },
      "source": [
        "data = pd.read_csv('./drive/My Drive/data1.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "fGnZIs1yXGSJ",
        "outputId": "1ec63222-20e9-4642-a8fa-9c661ff85d45"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>من با خانواده ام 4 شب در هتل داریوش اقامت داشت...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>من به همراه همسرم و پسر و مادرم شهریور به مدت ...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>اتاق ما بزرگی اش خوب بود .کیفیت غذای رستوران خ...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>در تاريخ 23 لغايت 27 مرداد94 به مدت چهار روز ب...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>سلام من و خانواده ام در مرداد 94 درهتل داریوش ...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text Sentiment\n",
              "0  من با خانواده ام 4 شب در هتل داریوش اقامت داشت...       pos\n",
              "1  من به همراه همسرم و پسر و مادرم شهریور به مدت ...       pos\n",
              "2  اتاق ما بزرگی اش خوب بود .کیفیت غذای رستوران خ...       pos\n",
              "3  در تاريخ 23 لغايت 27 مرداد94 به مدت چهار روز ب...       pos\n",
              "4  سلام من و خانواده ام در مرداد 94 درهتل داریوش ...       pos"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jrB6S0eUsk4"
      },
      "source": [
        "clean_data = {'Text':[], 'Sentiment':[]}\n",
        "for i in range(len(data['Text'])):\n",
        "  if(not isinstance(data['Text'][i], float) and len(data['Text'][i].split(\" \")) <= 150 and i != 13996):\n",
        "    clean_data['Text'].append(data['Text'][i])\n",
        "    clean_data['Sentiment'].append(data['Sentiment'][i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Lqmp5mYZPTx"
      },
      "source": [
        "clean_data['Test'] = [x.replace(\":;،,><؟?.\", \"\") for x in clean_data['Text']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0ZFmebmZjCk"
      },
      "source": [
        "for i in range(len(clean_data['Sentiment'])):\n",
        "  if(clean_data['Sentiment'][i] == 'pos'):\n",
        "    clean_data['Sentiment'][i] = [1, 0]\n",
        "  else:\n",
        "    clean_data['Sentiment'][i] = [0, 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRN1w6aHZ4bK"
      },
      "source": [
        "max_features = 1500\n",
        "tokenizer = Tokenizer(num_words=max_features, split=' ')\n",
        "tokenizer.fit_on_texts(clean_data['Text'])\n",
        "X = tokenizer.texts_to_sequences(clean_data['Text'])\n",
        "X = pad_sequences(X)\n",
        "# X[:2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIRQHCMGhftR"
      },
      "source": [
        "reverse_word_map = dict(map(reversed, tokenizer.word_index.items()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBWHajP6gFWO"
      },
      "source": [
        "Y = []\n",
        "for x in X:\n",
        "  temp = []\n",
        "  for word in x:\n",
        "    a = reverse_word_map[word]\n",
        "    temp.append(word)\n",
        "    if(a in sentiment):\n",
        "      temp.append(sentiment[a][0])\n",
        "      temp.append(sentiment[a][1])\n",
        "    else:\n",
        "      temp.append(0)\n",
        "      temp.append(0)\n",
        "  Y.append(temp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiUTqoKTitVl"
      },
      "source": [
        "X = pad_sequences(Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVacSZYwaSj_",
        "outputId": "2ff4ce7e-7a07-4a6f-9ff9-6ab559d87d5a"
      },
      "source": [
        "embed_dim = 128\n",
        "lstm_out = 196\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, embed_dim,input_length = X.shape[1]))\n",
        "model.add(SpatialDropout1D(0.4))\n",
        "model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(2,activation='softmax'))\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_9 (Embedding)      (None, 146, 128)          192000    \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d (SpatialDr (None, 146, 128)          0         \n",
            "_________________________________________________________________\n",
            "lstm_18 (LSTM)               (None, 196)               254800    \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 2)                 394       \n",
            "=================================================================\n",
            "Total params: 447,194\n",
            "Trainable params: 447,194\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9LiVAY0ir0r",
        "outputId": "57f2982d-214a-49e1-ffe0-f39d39e710ee"
      },
      "source": [
        "# this is the placeholder tensor for the input sequences\n",
        "sequence = Input(shape=(X.shape[1],), dtype='int32')\n",
        "# this embedding layer will transform the sequences of integers\n",
        "# into vectors of size 128\n",
        "embedded = Embedding(max_features, 128, input_length=X.shape[1])(sequence)\n",
        "\n",
        "# apply forwards LSTM\n",
        "forwards = LSTM(30)(embedded)\n",
        "# apply backwards LSTM\n",
        "backwards = LSTM(30, go_backwards=True)(embedded)\n",
        "\n",
        "# concatenate the outputs of the 2 LSTMs\n",
        "# merged = merge([forwards, backwards], mode='concat', concat_axis=-1)\n",
        "merged = Concatenate()([forwards, backwards])\n",
        "after_dp = Dropout(0.5)(merged)\n",
        "output = Dense(2, activation='sigmoid')(after_dp)\n",
        "\n",
        "model = Model(inputs=sequence, outputs=output)\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 146)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 146, 128)     192000      input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   (None, 30)           19080       embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lstm_3 (LSTM)                   (None, 30)           19080       embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 60)           0           lstm_2[0][0]                     \n",
            "                                                                 lstm_3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 60)           0           concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 2)            122         dropout_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 230,282\n",
            "Trainable params: 230,282\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4N7h9XIawNl",
        "outputId": "aba0f6b1-c9b3-44f1-ce53-ee1b8c40d08c"
      },
      "source": [
        "Y = clean_data['Sentiment']\n",
        "Y = np.array(Y)\n",
        "print(Y)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.20)\n",
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "Y_train = np.array(Y_train)\n",
        "Y_test = np.array(Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " ...\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFDeJynbbuiz",
        "outputId": "4d50d467-39e2-4865-ac6e-933904292d61"
      },
      "source": [
        "print(X_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(12046, 146)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2kj3VYbsYIa",
        "outputId": "2c0a8d93-ca8c-4e28-e887-ba96599f311c"
      },
      "source": [
        "#one direction\n",
        "batch_size = 128\n",
        "model.fit(X_train, Y_train, epochs = 10, batch_size=batch_size, verbose = 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "95/95 [==============================] - 27s 245ms/step - loss: 0.6598 - accuracy: 0.6212\n",
            "Epoch 2/10\n",
            "95/95 [==============================] - 23s 242ms/step - loss: 0.3639 - accuracy: 0.8616\n",
            "Epoch 3/10\n",
            "95/95 [==============================] - 23s 244ms/step - loss: 0.2506 - accuracy: 0.9112\n",
            "Epoch 4/10\n",
            "95/95 [==============================] - 23s 245ms/step - loss: 0.2070 - accuracy: 0.9267\n",
            "Epoch 5/10\n",
            "95/95 [==============================] - 23s 244ms/step - loss: 0.1824 - accuracy: 0.9376\n",
            "Epoch 6/10\n",
            "95/95 [==============================] - 23s 247ms/step - loss: 0.1671 - accuracy: 0.9407\n",
            "Epoch 7/10\n",
            "95/95 [==============================] - 23s 246ms/step - loss: 0.1547 - accuracy: 0.9461\n",
            "Epoch 8/10\n",
            "95/95 [==============================] - 23s 247ms/step - loss: 0.1346 - accuracy: 0.9554\n",
            "Epoch 9/10\n",
            "95/95 [==============================] - 23s 246ms/step - loss: 0.1401 - accuracy: 0.9508\n",
            "Epoch 10/10\n",
            "95/95 [==============================] - 24s 248ms/step - loss: 0.1186 - accuracy: 0.9572\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f28c6357650>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "id": "tF3qOgtWbfuE",
        "outputId": "0c0115f7-903d-4f89-8dee-010384a4eea0"
      },
      "source": [
        "#bi directional\n",
        "batch_size = 128\n",
        "model.fit(X_train, Y_train, epochs = 10, batch_size=batch_size, verbose = 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-5d5021581903>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#bi directional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1156\u001b[0m                 _r=1):\n\u001b[1;32m   1157\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2F1GooZeCWL"
      },
      "source": [
        "Y_pred = model.predict(X_test,batch_size = batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZRB8je8qoxr"
      },
      "source": [
        "Y_pred = Y_pred.argmax(axis=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "naTD2u8lszjg",
        "outputId": "0d1b2807-e4ed-4790-ae4e-bb1503ba20f1"
      },
      "source": [
        "#one direction\n",
        "df_test = pd.DataFrame({'true': Y_test.tolist(), 'pred':Y_pred})\n",
        "df_test['true'] = df_test['true'].apply(lambda x: np.argmax(x))\n",
        "print(\"confusion matrix\",confusion_matrix(df_test.true, df_test.pred))\n",
        "print(classification_report(df_test.true, df_test.pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "confusion matrix [[1181  123]\n",
            " [ 161 1547]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.91      0.89      1304\n",
            "           1       0.93      0.91      0.92      1708\n",
            "\n",
            "    accuracy                           0.91      3012\n",
            "   macro avg       0.90      0.91      0.90      3012\n",
            "weighted avg       0.91      0.91      0.91      3012\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYbx-bYOrjAH",
        "outputId": "60e6eb8b-6bef-411a-e435-9b50499a60f5"
      },
      "source": [
        "#bi directional\n",
        "df_test = pd.DataFrame({'true': Y_test.tolist(), 'pred':Y_pred})\n",
        "df_test['true'] = df_test['true'].apply(lambda x: np.argmax(x))\n",
        "print(\"confusion matrix\",confusion_matrix(df_test.true, df_test.pred))\n",
        "print(classification_report(df_test.true, df_test.pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "confusion matrix [[1159  125]\n",
            " [ 214 1514]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.90      0.87      1284\n",
            "           1       0.92      0.88      0.90      1728\n",
            "\n",
            "    accuracy                           0.89      3012\n",
            "   macro avg       0.88      0.89      0.89      3012\n",
            "weighted avg       0.89      0.89      0.89      3012\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1DqQVS3Kjrv",
        "outputId": "5ccc0db3-1eec-4279-9274-2d1d80d30326"
      },
      "source": [
        "# print(Y_pred)\n",
        "# print(Y_test)\n",
        "correct = 0\n",
        "for i in range(len(Y_test)):\n",
        "  if(Y_pred[i] != Y_test[i][0]):\n",
        "    correct += 1\n",
        "print(correct / len(Y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8824701195219123\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nHTU9VMLgew"
      },
      "source": [
        "A = []\n",
        "for i in range(len(Y_test)):\n",
        "  if(Y_pred[i] == Y_test[i][0]):\n",
        "    A.append(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huloIEXKMcdC",
        "outputId": "0be663f8-3d78-4141-dcbc-d1687c6402f6"
      },
      "source": [
        "print(A)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[9, 13, 18, 30, 46, 51, 53, 73, 82, 93, 102, 111, 114, 123, 129, 141, 147, 153, 157, 160, 163, 171, 172, 177, 198, 209, 210, 213, 223, 227, 230, 240, 275, 294, 311, 319, 331, 361, 366, 368, 373, 384, 385, 388, 394, 415, 431, 451, 461, 462, 466, 472, 473, 482, 493, 503, 514, 522, 526, 529, 549, 563, 579, 589, 590, 594, 604, 606, 607, 618, 628, 650, 661, 666, 667, 671, 682, 688, 693, 694, 696, 700, 702, 707, 719, 724, 726, 728, 737, 744, 769, 774, 775, 798, 803, 810, 874, 889, 893, 903, 910, 918, 919, 926, 941, 943, 964, 966, 992, 996, 1012, 1014, 1031, 1036, 1037, 1042, 1063, 1064, 1072, 1089, 1094, 1097, 1103, 1104, 1107, 1115, 1116, 1122, 1124, 1128, 1130, 1148, 1205, 1209, 1224, 1237, 1238, 1245, 1255, 1262, 1274, 1286, 1290, 1305, 1307, 1311, 1315, 1321, 1326, 1327, 1333, 1343, 1344, 1347, 1359, 1360, 1384, 1398, 1411, 1412, 1414, 1433, 1446, 1447, 1473, 1479, 1495, 1509, 1512, 1513, 1514, 1523, 1532, 1553, 1565, 1577, 1578, 1589, 1600, 1607, 1608, 1615, 1622, 1628, 1630, 1631, 1638, 1642, 1644, 1645, 1648, 1660, 1668, 1677, 1698, 1700, 1703, 1721, 1725, 1729, 1730, 1732, 1737, 1747, 1750, 1753, 1762, 1764, 1781, 1795, 1806, 1807, 1819, 1842, 1843, 1849, 1861, 1866, 1905, 1909, 1920, 1936, 1940, 1942, 1944, 1959, 1972, 1980, 1986, 1997, 2008, 2014, 2016, 2026, 2038, 2055, 2060, 2067, 2072, 2090, 2094, 2097, 2102, 2104, 2108, 2116, 2118, 2120, 2125, 2126, 2141, 2145, 2147, 2148, 2149, 2152, 2160, 2168, 2172, 2178, 2182, 2189, 2198, 2228, 2240, 2244, 2246, 2268, 2277, 2289, 2304, 2313, 2316, 2323, 2365, 2395, 2420, 2423, 2426, 2435, 2436, 2437, 2442, 2446, 2470, 2471, 2473, 2476, 2483, 2487, 2494, 2500, 2502, 2510, 2512, 2519, 2540, 2543, 2547, 2548, 2566, 2572, 2604, 2641, 2644, 2645, 2661, 2663, 2669, 2686, 2693, 2697, 2703, 2709, 2716, 2717, 2728, 2746, 2753, 2768, 2769, 2773, 2774, 2776, 2791, 2794, 2795, 2817, 2824, 2825, 2832, 2835, 2836, 2840, 2849, 2859, 2866, 2870, 2873, 2887, 2911, 2912, 2920, 2925, 2931, 2939, 2954, 2963, 2980, 2993, 2994, 3001, 3005, 3007]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39DpWm9SMsdM",
        "outputId": "b0c793ed-acbb-45b9-ff8c-d6775e649676"
      },
      "source": [
        "print(Y_test[9])\n",
        "B = []\n",
        "for j in X_test[9]:\n",
        "  if(j >= 1):\n",
        "    B.append(reverse_word_map[j])\n",
        "print(B)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1]\n",
            "['سلام', 'همه', 'چيز', 'داخل', 'اتاق', 'بد', 'بود', 'نظافت', 'سرويس', 'بهداشتي', 'خراب', 'بودن', 'توالت', 'اتاق', 'چون', 'نداشت', 'اتاق', 'و', 'رستورانش', 'هم', 'با', 'توجه', 'به', 'هتل', '5', 'ستاره', 'كيفيت', 'نداشت', 'بسيار', 'شلوغ', 'و', 'از', 'آرامش', 'هتل', 'بسيار', 'بسيار', 'بهتر', 'بود']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5joQtn0XLp9x",
        "outputId": "f26936a1-0e97-4a9d-ddc7-40e1b2d2087f"
      },
      "source": [
        "# print(A)\n",
        "# print(X_test[16])\n",
        "print(Y_test[183])\n",
        "B = []\n",
        "for j in X_test[183]:\n",
        "  if(j >= 1):\n",
        "    B.append(reverse_word_map[j])\n",
        "print(B)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1]\n",
            "['ما', 'به', 'مدت', 'در', 'این', 'هتل', 'بودیم', 'البته', 'این', 'نظر', 'نیست', 'و', 'ما', 'همین', 'نظر', 'را', 'دارند', 'از', 'بابت', 'تمیزی', 'که', 'مهم', 'هم', 'هست', 'خیلی', 'بد', 'بود', 'و', 'وسایل', 'داخل', 'از', 'سرویس', 'خواب', 'تا', 'راحتی', 'در', 'ورود', 'صد', 'درصد', 'پشیمان', 'کننده', 'بود', 'نزدیک', 'بودن', 'ساحل', 'خوب', 'و', 'کارکنان', 'رستوران', 'خوب', 'بودند', 'ساعت', 'صبحانه', '7', '9', 'بود', 'هزینه', 'هتل', 'خوب', 'بود', 'قیمت', 'غذا', 'و', 'مناسب', 'بود', 'و', 'کیفیت', 'متوسط', 'و', 'جالب', 'و', 'سوال', 'من', 'که', '3ستاره', 'نبود', 'یا', 'بود', 'ما', '3ستاره', 'بودیم', 'برای', 'تهیه', 'تفریحی', 'از', 'خود', 'بگیرید', 'اگه', 'راست', 'میگن', 'درکل', 'محیط', 'مناسب', 'و', 'نامناسب', 'بود']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SF7MxFyJ6Uv",
        "outputId": "7522699b-6d42-43a4-d875-25d074a8daa0"
      },
      "source": [
        "model.save('./drive/My Drive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./drive/My Drive/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./drive/My Drive/assets\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}